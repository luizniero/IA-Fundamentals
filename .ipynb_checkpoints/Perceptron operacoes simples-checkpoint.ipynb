{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eba6637-8365-454d-8c9b-df68be8e67ef",
   "metadata": {},
   "source": [
    "#### Atividade1 : Implementando um Perceptron\n",
    "\n",
    "Discente: Luiz Henrique Pereira Niero\n",
    "Docente: Prof. Dr. LucasC. Ribas\n",
    "PPGCC - Unesp - 2025\n",
    "Disciplina: Rdes Neurais Artificiais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99fe7282-ff1f-4636-a123-f23a41169dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc83b13f-613e-463e-8fb4-3a427163f8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__ (self, x_train, y_train, tx_aprendizado, num_epocas):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.tx_aprendizagem = tx_aprendizado\n",
    "        self.qtde_epocas = num_epocas\n",
    "        \n",
    "        self.quantidade_elementos_treino = x_train.shape[0]\n",
    "        self.quantidade_atributos = x_train.shape[1] \n",
    "        self.w = np.random.uniform(0, 0.2, size=self.quantidade_atributos)\n",
    "        self.limiar = random.uniform(0, 0.2) # ponto flutuante entre 0 e 0.2\n",
    "        self.erros = 0\n",
    "        self.w_epocas = []\n",
    "        self.bias_epocas = []\n",
    "        self.erros_epocas = []\n",
    "\n",
    "\n",
    "    # Ajusta os pesos para uma linha da matriz de entrada (aqui uma linha corresponde a um elemento x do conjunto X de treinamento)\n",
    "    # Retorna 1 se a predição foi correta e 0 se a predição foi errada\n",
    "    def treina_elemento(self, indice):\n",
    "        gux = 0\n",
    "        wx = 0\n",
    "        y = self.y_train[indice]\n",
    "    \n",
    "        # Itera por cada elemento i de xi e wi e faz a soma em wx.\n",
    "        for i in range(self.quantidade_atributos):\n",
    "            wxi = self.x_train[indice][i] * self.w[i]\n",
    "            wx += wxi\n",
    "    \n",
    "        wx = wx + self.limiar\n",
    "        \n",
    "        if wx >= 0:\n",
    "            gux = 1\n",
    "        else:\n",
    "            gux = -1\n",
    "    \n",
    "        if y == gux:\n",
    "            return 1\n",
    "        else:\n",
    "            diferenca = y - gux\n",
    "            ajuste_base = self.tx_aprendizagem * diferenca\n",
    "\n",
    "            # Ajusta cada elemento do vetor W\n",
    "            for j in range (self.quantidade_atributos):\n",
    "                self.w[j] = self.w[j] + ajuste_base * self.x_train[indice][j]\n",
    "            \n",
    "            # Ajusta o bias\n",
    "            self.limiar = self.limiar + ajuste_base\n",
    "            return 0\n",
    "\n",
    "\n",
    "    def treina_epoca(self, epoca):\n",
    "        acertos_da_epoca = 0\n",
    "        erros_da_epoca = 0\n",
    "        \n",
    "        for i in range(self.quantidade_elementos_treino):\n",
    "            acertos_da_epoca += self.treina_elemento(i)\n",
    "\n",
    "        # salvando os pesos da época.\n",
    "        self.w_epocas.append(self.w.copy())\n",
    "        self.bias_epocas.append(self.limiar.copy())\n",
    "        erros_da_epoca = self.quantidade_elementos_treino - acertos_da_epoca\n",
    "        self.erros_epocas.append(erros_da_epoca)\n",
    "        \n",
    "        self.erros = erros_da_epoca\n",
    "        #print(f\"Época {epoca}. Acertos: {acertos_da_epoca} Erros: {erros_da_epoca}. Taxa de acertos: {acertos_da_epoca / self.quantidade_elementos_treino}\")          \n",
    "\n",
    "\n",
    "    def treina(self):\n",
    "        for epoca in range(self.qtde_epocas):\n",
    "            self.treina_epoca(epoca)\n",
    "\n",
    "        print(\"\\r\\n --- Resultados do treinamento --- \")\n",
    "        melhor_epoca =  self.erros_epocas.index(min(self.erros_epocas))\n",
    "        melhor_w = self.w_epocas[melhor_epoca]\n",
    "        melhor_bias = self.bias_epocas[melhor_epoca]\n",
    "        erros_melhor_epoca = self.erros_epocas[melhor_epoca]\n",
    "        tx_acerto_melhor_epoca = (self.quantidade_elementos_treino - erros_melhor_epoca) / self.quantidade_elementos_treino\n",
    "        \n",
    "        print(f\"Melhor época: {melhor_epoca}\")\n",
    "        print(f\"Quantidade de erros: {erros_melhor_epoca}\")        \n",
    "        print(f\"Taxa de acertos da melhor época: {tx_acerto_melhor_epoca}\")\n",
    "        print(f\"Melhores pesos: {melhor_w}\")\n",
    "        print(f\"Melhor bias: {melhor_bias}\")\n",
    "\n",
    "        epocas = range(1, len(self.erros_epocas) + 1)\n",
    "        tx_erros = [(erro / len(self.erros_epocas)) for erro in self.erros_epocas]\n",
    "        \n",
    "        plt.plot(epocas, tx_erros, marker='o', linestyle='-')\n",
    "        plt.xlabel('Épocas')\n",
    "        plt.ylabel('% erro')\n",
    "        plt.title('Erro ao longo das Épocas de Treinamento')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def testa(self, x_test, y_test):\n",
    "        melhor_epoca =  self.erros_epocas.index(min(self.erros_epocas))\n",
    "        \n",
    "        w = self.w_epocas[melhor_epoca]\n",
    "        b = self.bias_epocas[melhor_epoca]\n",
    "        \n",
    "        quantidade_elementos_teste = x_test.shape[0]\n",
    "        acertos = 0\n",
    "        \n",
    "        for i in range (quantidade_elementos_teste):\n",
    "            xw = 0 #Somatória wixi + bias com i = 0:n.\n",
    "            y = y_test[i] # Valor esperado\n",
    "            \n",
    "            # Soma cada atributo * peso do elemento\n",
    "            for j in range (self.quantidade_atributos):\n",
    "                # xwj = xj * wj\n",
    "                xwj = x_test[i][j] * w[j]\n",
    "                xw += xwj\n",
    "            xw += b\n",
    "\n",
    "            # Função degrau g(xw)\n",
    "            if (xw >= 0):\n",
    "                gxw = 1\n",
    "            else:\n",
    "                gxw = -1\n",
    "\n",
    "\n",
    "            # Verifica se acertou ou errou a predição do elemento i\n",
    "            if gxw == y:\n",
    "                acertos += 1\n",
    "\n",
    "        print(\"Resultados dos testes : \")\n",
    "        print(f\"Total de elementos: {quantidade_elementos_teste}\")\n",
    "        print(f\"Total de predições corretas: {acertos}\")\n",
    "        print(f\"Taxa de acertos: {acertos / quantidade_elementos_teste}\")\n",
    "    \n",
    "\n",
    "    def plota_grafico(self, X, Y, titulo):\n",
    "        melhor_epoca = self.erros_epocas.index(min(self.erros_epocas))\n",
    "        w = self.w_epocas[melhor_epoca]\n",
    "        b = self.bias_epocas[melhor_epoca]\n",
    "    \n",
    "        # Definindo um intervalo para x1 baseado nos dados\n",
    "        x1_min = X[:, 0].min() - 1\n",
    "        x1_max = X[:, 0].max() + 1\n",
    "\n",
    "        # dimensões x1 e x2 da linha\n",
    "        linha_x1 = np.linspace(x1_min, x1_max, 100)\n",
    "        linha_x2 = -(w[0] * linha_x1 + b) / w[1]\n",
    "        \n",
    "        # Separando os pontos por classe para melhor visualização\n",
    "        X_pos = X[Y == 1]\n",
    "        X_neg = X[Y == -1]\n",
    "        \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.scatter(X_pos[:, 0], X_pos[:, 1], color='blue', label='Classe 1')\n",
    "        plt.scatter(X_neg[:, 0], X_neg[:, 1], color='red', label='Classe -1')\n",
    "        \n",
    "        # Plotando a reta de decisão\n",
    "        plt.plot(linha_x1, linha_x2, 'k-', label='Reta de decisão')\n",
    "        \n",
    "        plt.xlabel('Atributo 1')\n",
    "        plt.ylabel('Atributo 2')\n",
    "        plt.title(f'Elementos e reta de Separação do Perceptron - {titulo}')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d25f451-7673-457f-8456-e6186369dc7f",
   "metadata": {},
   "source": [
    "#### Instancia e treina o Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cf158a9-8523-4c02-b04b-ce9a098883e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " --- Resultados do treinamento --- \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'perceptron' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Recebe um vetor X e o valor previsto Y e atualiza os parâmetros W e Bias.\u001b[39;00m\n\u001b[0;32m     17\u001b[0m perceptron1 \u001b[38;5;241m=\u001b[39m Perceptron(x_train, y_train, tx_aprendizado, num_epocas)\n\u001b[1;32m---> 18\u001b[0m \u001b[43mperceptron1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtreina\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 74\u001b[0m, in \u001b[0;36mPerceptron.treina\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtreina_epoca(epoca)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m --- Resultados do treinamento --- \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 74\u001b[0m melhor_epoca \u001b[38;5;241m=\u001b[39m  \u001b[43mperceptron\u001b[49m\u001b[38;5;241m.\u001b[39merros_epocas\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mmin\u001b[39m(perceptron\u001b[38;5;241m.\u001b[39merros_epocas))\n\u001b[0;32m     75\u001b[0m melhor_w \u001b[38;5;241m=\u001b[39m perceptron\u001b[38;5;241m.\u001b[39mw_epocas[melhor_epoca]\n\u001b[0;32m     76\u001b[0m melhor_bias \u001b[38;5;241m=\u001b[39m perceptron\u001b[38;5;241m.\u001b[39mbias_epocas[melhor_epoca]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'perceptron' is not defined"
     ]
    }
   ],
   "source": [
    "dataset_treinamento = 'perceptron_datasets\\\\train_dataset1.csv'\n",
    "dataset_testes = 'perceptron_datasets\\\\test_dataset1.csv'\n",
    "\n",
    "df_train_loaded = pd.read_csv(dataset_treinamento)\n",
    "df_test_loaded = pd.read_csv(dataset_testes)\n",
    "\n",
    "x_train = df_train_loaded.drop('label', axis=1).values\n",
    "y_train = df_train_loaded['label'].values\n",
    "\n",
    "x_test = df_test_loaded.drop('label', axis=1).values\n",
    "y_test = df_test_loaded['label'].values\n",
    "\n",
    "tx_aprendizado = 0.1\n",
    "num_epocas = 100\n",
    "\n",
    "# Recebe um vetor X e o valor previsto Y e atualiza os parâmetros W e Bias.\n",
    "perceptron1 = Perceptron(x_train, y_train, tx_aprendizado, num_epocas)\n",
    "perceptron1.treina()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7938261f-d017-4590-946d-79005c9e9f86",
   "metadata": {},
   "source": [
    "#### Testa o perceptron treinado contra o conjunto de testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030ba756-2db4-4f96-810d-73e2fedec59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron1.testa(x_test, y_test)\n",
    "perceptron1.plota_grafico(x_test, y_test, 'Testes')\n",
    "perceptron1.plota_grafico(x_train, y_train, 'Treinamento')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2314ca-5e27-4b6b-998f-3b2916bc9fba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c50121a-323d-4d59-8f92-54af6bd04112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
